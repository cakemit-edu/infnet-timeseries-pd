---
title:  Projeto da disciplina - Séries Temporais
author: Claudia Tanaka (claudia.tanaka@al.infnet.edu.br)
date:   "Atualizado em `r format(Sys.time(), '%d/%m/%Y')`"

output:
  html_notebook:
    toc: yes
    toc_depth: 4
    toc_float: yes
    # code_folding: hide
---

*Desenvolvido em R versão 4.3.2 (2023-10-31 ucrt)*

```{r setup, include=FALSE}
knitr::opts_chunk$set( message=FALSE, warning=FALSE )
options(scipen=999) # "Desliga" notação científica. 

# PRETTY DOC
library(gt)
library(patchwork)
library(fpp3)

theme_set(theme_light())
theme_update(
  panel.grid.minor = element_blank(),
  panel.grid.major = element_line(colour = "gray95"),
  plot.title = element_text(size = 10, colour = "gray30", face = "bold"),
  plot.subtitle = element_text(face = 'italic', colour = "gray50", size = 10),
  plot.caption = element_text(colour = "gray50", hjust=0, size = 8),
  legend.title = element_blank(),
  axis.title = element_text(size = 8)
)
```


\

# Introdução

Nessa disciplina, aprofundamos nossos conhecimentos em séries temporais, tarefa que é extremamente importante para o dia-a-dia de um cientista de dados. Agora iremos validar nosso conhecimento. 

Para a realização desse trabalho, será necessário utilizar a plataforma Knime e seus componentes para análise de séries temporais. Para tal, será necessário ter Python instalado em sua máquina e fazer a integração com a plataforma (sugestão: Anaconda)

Escolha uma base de dados para realizar esse projeto. Essa base de dados será utilizada durante toda sua análise. Essa base necessita ter 2 (ou mais) variáveis de interesse. Fundamental que a ordem das entradas seja importante (uma das entradas é sequencial ou temporal). Caso você tenha dificuldade para escolher uma base, a professora da disciplina irá designar para você.


```{r}
# Pacotes R utilizados nesse projeto
library(fpp3)

```

\

# P01 Knime/Python

\

**No relatório final, anexe um printscreen evidenciando que o Knime está funcionando com os componentes e integrado com Python**

\

![](.imgs/knime1.png)

\

# P02 Base

\

**Explique a motivação de uso da base escolhida. Quais perguntas (problemas) são respondidos nessa base com o uso de séries temporais? Cite ao menos duas perguntas.**

Esse projeto estuda a evolução do volume de produção trimestral de alguns setores da economia brasileira, segundo divulgado pelo IBGE. 

Há diferenças nos padrões de tendência entre o PIB dos setores da economia? Quais setores apresentam maior sazonalidade? Qual a relação entre o PIB de um setor com o PIB de outro setor? Essas são algumas perguntas que podem ser respondidas com o uso de séries temporais.

\

# P03 Variáveis

\

**Descreva as variáveis presentes na base. Quais são as variáveis? Quais são os tipos de variáveis (discreta, categórica, contínua)? Quais são as médias e desvios padrões?**

\

Os dados informados são uma série temporal encadeada do índice de volume de produção trimestral em cada setor da economia, indexado à base $100 = média\ trimestral\ do\ ano\ de\ 1995$, disponibilizados pelo IBGE em  [https://sidra.ibge.gov.br/home/cnt/brasil]. 

Os três setores da economia são [Indústria]{.underline}, [Serviços]{.underline} e [Agropecuária]{.underline}, identificados pela variável categórica `name`.

O volume de produção trimestral é uma variável numérica contínua e está identificado na base pelo campo `producao`.

O campo de data `Trimestre` é uma variável sequencial, que representa o trimestre de cada observação.

\

A base contém 112 observações para cada setor da economia, que correspondem aos 112 trimestres entre 1ºT de 1996 e 4ºT 2023, totalizando 336 observações. Não há lacunas nessas três séries temporais. 


```{r}
(ts1 <- readr::read_delim("_datasets/tabela1620.csv", delim=",", show_col_types=F, skip=4) |> 
  # Limpa e formata os dados
  filter(!is.na(`Comércio`)) |> 
  mutate(across(2:23, as.numeric)) |> 
  
  # Formata o campo "setor" e o campo "produção"
  pivot_longer(2:23, names_to="setor", values_to="producao") |> # Coloca as séries empilhadas
  mutate(setor = stringr::str_remove(setor, " - total")) |>
  
  # Formata o campo "Trimestre"
  mutate(n.trim = as.numeric(stringr::str_sub(Trimestre,1,1)),
         ano = as.integer(paste0(stringr::str_sub(Trimestre,-4,-1)))) |> 
  mutate(Trimestre = make_yearquarter(ano, n.trim)) |> 
  
  # Finaliza a tabela
  select(Trimestre, setor, producao) |> 
  filter(setor %in% c("Indústria", "Serviços", "Agropecuária")) |> 
  arrange(setor, Trimestre) |> 
  
  # Transforma em um objeto série temporal
  as_tsibble(index=Trimestre, key=setor))
```


\

A seguir um resumo estatístico da série temporal incluindo as médias e desvios padrões:

```{r}
summarytools::descr(ts1 |> group_by(setor))
```


\

# P04 Conceitos

\

**Com suas palavras explique:**\

\

**a. Processo estocástico**

Na teoria da probabilidade, um processo estocástico ou aleatório é um objeto matemático geralmente definido como uma sequência de variáveis aleatórias em um espaço de probabilidade, onde o índice ou eixo da sequência é uma medida de tempo. Processos estocásticos são amplamente utilizados como modelos matemáticos de sistemas e fenômenos que parecem variar de maneira aleatória. Exemplos incluem o crescimento de uma população bacteriana, uma corrente elétrica flutuando devido a ruído térmico ou o movimento de uma molécula de gás. (Parzen 2015)

\

**b. Processo determinístico**

"Determinístico" refere-se a um sistema ou processo totalmente previsível e que segue um conjunto de regras ou leis. Assim sendo, dado um certo ponto de partida conhecido (input), um sistema determinístico produzirá sempre o mesmo resultado. Isso ocorre porque o comportamento de um sistema determinístico é inteiramente determinado por suas entradas (inputs) e pelas regras que governam sua operação. Não há nenhum elemento de acaso ou aleatoriedade envolvido em um sistema determinístico.

Em outras palavras, se as condições iniciais e as regras que regem o processo determinístico forem conhecidas, será possível prever com certeza qual será o resultado. 


\


**c. Sazonalidade estocástica**

**d. Sazonalidade determinística**

Sazonalidade em uma série temporal refere-se a movimentos sistemáticos de uma variável observada ao longo do tempo que se repetem durante um determinado período com intensidade semelhante. Um padrão sazonal ocorre quando uma série temporal é afetada por fatores sazonais, como a época do ano, o dia da semana ou a hora do dia. 

A sazonalidade pode ser classificada em dois tipos: sazonalidade determinística e sazonalidade estocástica.

As séries temporais com sazonalidade determinística apresentam um padrão sazonal constante que sempre se repete de forma previsível, tanto em intensidade (o nível do padrão sazonal permanece o mesmo durante o mesmo período sazonal) quanto em periodicidade (a localização dos picos e vales não muda, isto é, o tempo entre cada repetição do padrão sazonal é constante). (Cerqueira, 2023)

Por outro lado, as séries temporais com sazonalidade estocástica apresentam um padrão sazonal que varia de forma aleatória, tanto em intensidade quanto em periodicidade. Isso significa que o padrão sazonal pode mudar de intensidade ou de periodicidade de um período sazonal para o outro, tornando a previsão do padrão sazonal mais desafiadora.


\

**e. Sazonalidade aditiva vs multiplicativa**

A decomposição aditiva é uma técnica de análise de séries temporais que divide uma série temporal em três componentes: tendência, sazonalidade e ruído. A decomposição aditiva é aplicável quando a magnitude das flutuações sazonais, ou a variação em torno do ciclo de tendência, não varia com o nível da série temporal. (Hyndman & Athanasopoulos, 2021)

A decomposição aditiva é expressa pela seguinte equação:

$$
Y_t = Tendência_t + Sazonalidade_t + Ruído_t
$$

Quando a variação no padrão sazonal, ou a variação em torno do ciclo de tendência, apresentam um comportamento estocástico que parece ser proporcional ao nível da série temporal, então uma decomposição multiplicativa é mais apropriada. (Hyndman & Athanasopoulos, 2021)

A decomposição multiplicativa é expressa pela seguinte equação:

$$
Y_t = Tendência_t \times Sazonalidade_t \times Ruído_t
$$



\

# P05 Visualização

\

**Em relação à base escolhida:**\

\

## Variáveis

**a. Faça gráficos onde cada variável não sequencial é usada no eixo-Y e a sequencial é o eixo-X**


```{r fig.asp=.5}
ts1 |> 
  autoplot(producao) +
  scale_y_continuous(labels=scales::label_number()) +
  scale_color_brewer(palette="Dark2") +
  labs(y="Volume de produção (1995=100)", title="Índice de produção trimestral por setor da economia")
```

\

## Autocorrelações

**b. Faça um gráfico de autocorrelação para cada uma das variáveis (ACF Plot)**
**c. Faça um gráfico de correlação parcial para cada uma das variáveis (PACF Plot)**

Agropecuária parece ter um forte componente sazonal e a amplitude da sazonalidade vem aumentando ao longo dos anos. Nota-se no gráfico ACF que a autocorrelação é significativa a cada 4 trimestres, o que sugere um padrão sazonal com período de 4 trimestres (sazonalidade anual). O gráfico PACF mostra que a autocorrelação anual é forte apenas no quarto lag, após retirar-se o efeito das autocorrelações dos outros lags. 

O setor agropecuário também tem uma autocorrelação significativa no primeiro lag, o que sugere que o volume de produção de um trimestre ajuda a explicar ou projetar o volume do trimestre seguinte.

```{r}
ts1 |> filter(setor=="Agropecuária") |> 
  gg_tsdisplay(producao, plot_type = "partial") +
  labs(title = "Índice de produção trimestral, Agropecuária", subtitle = "Gráficos de autocorrelação")
```


\


```{r}
ts1 |> filter(setor=="Serviços") |> 
  gg_tsdisplay(producao, plot_type = "partial") +
  labs(title = "Índice de produção trimestral, Serviços", subtitle = "Gráficos de autocorrelação")
```

\


```{r}
ts1 |> filter(setor=="Indústria") |> 
  gg_tsdisplay(producao, plot_type = "partial") +
  labs(title = "Índice de produção trimestral, Indústria", subtitle = "Gráficos de autocorrelação")
```

\

Visualmente, fica claro que nenhuma das três séries é estacionária. Podemos confirmar isso com testes estatísticos de raíz unitária:

```{r}
ts1 |> features(producao, unitroot_kpss)
```

KPSS: No teste Kwiatkowski-Phillips-Schmidt-Shin (KPSS) (Kwiatkowski et al., 1992) a hipótese nula é que os dados são estacionários e procuramos evidências de que a hipótese nula é falsa. Consequentemente, pequenos valores de p (por exemplo, menos de 0,05) sugerem que a diferenciação é necessária. O `p-value` do teste KPSS é relatado como um número entre 0,01 e 0,1. Se o `p-value` for inferior a 0,01, será relatado como 0,01; e se o `p-value` for superior a 0,1, é relatado como 0,1. Nesse caso, o `p-value` é apresentado como 0,01 (e portanto pode ser menor que isso), indicando que a hipótese nula é rejeitada. Ou seja, os dados não são estacionários. 


\

# P06 Decomposição

\

**Decomponha as variáveis em: Tendência, Sazonalidade e Resíduo. Faça um gráfico**

\

Nesse caso foi aplicada uma decomposição multiplicativa nos dados, que é mais adequada quando a amplitude da sazonalidade aumenta ou diminui em linha com aumento ou diminuição no nível da série. Na figura a seguir os três componentes - sazonalidade, tendência e resíduo - são mostrados separadamente nos três painéis inferiores. Na decomposição multiplicativa esses componentes podem ser multiplicados para reconstruir os dados originais mostrados no primeiro painel. 


```{r fig.asp=1.1}
ts1 |> 
  model(dcmp = classical_decomposition(producao, type="multiplicative")) |> 
  components() |> 
  autoplot() +
  theme(legend.position="top") +
  scale_x_yearquarter(date_breaks="5 years") +
  scale_color_brewer(palette="Dark2") +
  labs(title="Decomposição multiplicativa da série de produção por trimestre")
```


As barras cinzas à esquerda de cada painel mostram as escalas relativas dos componentes. Cada barra cinza representa o mesmo comprimento, mas como os gráficos estão em escalas diferentes, as barras variam em tamanho. A pequena barra cinza no painel de Tendência mostra que a variação neste componente é similar à variação nos dados originais do primeiro painel. Se encolhermos os dois painéis inferiores até que suas barras fiquem do mesmo tamanho que as do painel dos dados originais, todos os painéis estariam na mesma escala.

O setor agropecuário segue a maior tendência de alta entre os três setores nas últimas quase três décadas. De fato, no setor industrial e de serviços a tendência de crescimento parece se estagnar a partir de 2014.

A amplitude da sazonalidade (a diferença entre picos e vales) no setor agropecuário tende a aumentar progressivamente. Isso também ocorre, porém em menor amplitude, nos setores industrial e de serviços. Chama atenção a similaridade visual entre o comportamento da sazonalidade e da tendência do setor industrial e de serviços e sua distinção em relação ao setor agropecuário. O componente sazonal é mais forte no setor agropecuário com maior amplitude e com periodicidade bem marcada. Faz sentido, já que o setor agropecuário pode ser mais sensível a fatores sazonais, como a época de colheita ou condições climáticas.
 

A decomposição multiplicativa deixa a sazonalidade mais estável e faz com que as componentes de tendência e sazonalidade expliquem uma parcela grande da variabilidade dos dados. Dessa forma, o que sobra em termos de resíduo fica com picos e vales menores (uma variância mais estável), o que indica que os componentes de tendência e sazonalidade explicam parcela maior do comportamento das séries. 

A tendência aponta um crescimento quase linear no setor agropecuário e superior aos outros setores, mas parece surgir a ocorrência de dois vales em 2016 e 2022. Talvez seja o início de um comportamento cíclico com defasagem de 6 anos. Talvez isso tenha a ver com Mudanças climáticas cíclicas?

Nos setores industrial e de serviços a tendência de crescimento sofre estagnação a partir de 2014, mas o segmento de serviços parece mostrar indícios de recuperação em 2023, enquanto a indústria segue estagnada.


\

# P07 ARIMA

\

**Construa um modelo ARIMA para cada variável da base de dados e faça uma previsão (forecast) baseado nele. Use "Akaike Information Critera" para definir o melhor modelo ARIMA possível. Análise o resíduo do modelo de predição, com o número correto de graus de liberdade. (use os componentes ARIMA Predictor, ARIMA Learner e Analyze ARIMA Residuals)**


\

## Agropecuária

Separa datasets de treino e teste

```{r}
ts1.train <- ts1 |> filter(year(Trimestre)<=2019 & setor=="Agropecuária")
ts1.test <- ts1 |> filter(setor=="Agropecuária")
```


\


### 1. Modelagem


Tenta identificar por tentativa e erro o melhor modelo ARIMA usando a função `auto.arima` do pacote `forecast`.

```{r}
ts1.train |> model(AUTOARIMA = ARIMA(producao, trace=T)) |> report()
```


**Interpretando o modelo sugerido por autoarima** $ARIMA(0,0,1)(0,1,1)_4$:

$$
y^\prime_t = 5,52 + 0,44 \cdot \varepsilon_{t-1} + 0,41 \cdot \varepsilon_{t-4} + \varepsilon_t
$$

Isso significa que o modelo sugerido tem:

-   um componente de média móvel (MA) de ordem $q=1$, indicando que o modelo considera o resíduo do "fit" do trimestre imediatamente anterior com coeficiente estimado $ma_1 = 0,44$ e desvio padrão $0,1074$;

-   uma diferenciação de ordem $D=1$ da sazonalidade anual $s=4$, indicando aplicação de diferenciação do trimestre com o mesmo trimestre do ano anterior;

-   um componente de sazonalidade de ordem $P=0$ e $Q=1$, indicando que o modelo sugerido não faz autoregressão sazonal, mas considera o resíduo do "fit" do mesmo trimestre do ano anterior com coeficiente estimado $SMA_1 = 0,4064$ e desvio padrão $0,0875$.

-   O modelo estimou uma constante (*drift*) de $5,5155$ com desvio padrão de $0,8133$. O valor positivo da constante indica que o modelo permite que as projeções de valores futuros aumentem ao longo do tempo.

Nota: Esses desvios padrão me parecem relativamente baixos, o que poderia indicar certa precisão nas estimativas dos coeficientes.


O modelo sugerido não tem:

-   Componente Integração (I) $d=0$, que significa que não foi aplicada diferenciação com os trimestres imediatamente anteriores para tornar a série estacionária;

-   Componente Autocorrelação (AR) $p=0$, indicando que o modelo não usa os trimestres imediatamente anteriores para fazer previsões futuras;


\

**Critérios de comparação entre modelos:**

Critérios de informação como AIC e BIC são medidas relativas usadas para comparar o desempenho de vários modelos estatísticos entre si. Não existem valores de referência absolutos para AIC ou BIC que indiquem um bom modelo. Em vez disso, estes critérios são utilizados num sentido comparativo; entre um conjunto de modelos, geralmente deve-se favorecer o modelo com o AIC ou BIC mais baixo.


-   Critério de Informação de Akaike ou *Akaike Information Criterion* (AIC). Esse coeficiente penaliza a medida de ajuste do modelo com a quantidade de parâmetros que precisam ser estimados. Quanto mais parâmetros, maior o AIC. Quanto menor o AIC, melhor o modelo. 

-   AICC é o AIC corrigido para o tamanho da amostra. Semelhante ao AIC, ajusta o critério para o número de observações e é especialmente útil quando há poucas observações.

-   Critério de Informação Bayesiano ou *Bayesian Information Criterion* (BIC), penaliza pela quantidade de parâmetros utilizados, favorecendo modelos mais simples. O modelo escolhido pelo BIC é geralmente o mesmo escolhido pelo AIC ou um com menos termos. Isso ocorre porque o BIC penaliza mais fortemente o número de parâmetros do que o AIC.


Então vamos testar alguns modelos e compará-los com o modelo sugerido pelo `auto.arima`.

\

**Compara modelos:**


Constrói vários modelos para comparação entre si, tentando encontrar o modelo mais simples (menor número de parâmetros) com o melhor fit (menor erro residual nos dados de treino). A quantidade de parâmetros de um modelo é um indicativo de sua complexidade. Modelos mais complexos podem ser mais flexíveis e se ajustar melhor aos dados de treino, mas podem ter um desempenho pior na previsão de dados futuros (overfitting). No caso dos modelos SARIMA a quantidade de parâmetros é dada por $p+q+P+Q$.
 


```{r warning=FALSE}
fit.agr <- ts1.train |> 
  model(
    auto.arima     = ARIMA(producao ~ pdq(0,0,1) + PDQ(0,1,1,4)), # Modelo autoarima
    random.walk    = ARIMA(producao ~ pdq(0,1,0) + PDQ(0,1,0,4)), # Random Walk (naive forecast)
    auto.arima.ar1 = ARIMA(producao ~ pdq(1,0,1) + PDQ(0,1,1,4)), # Modelo autoarima + AR1
    sarima.I1      = ARIMA(producao ~ pdq(0,0,0) + PDQ(0,1,0,4)), # só diferenciação sazonal
    sarima.I1MA1   = ARIMA(producao ~ pdq(0,0,0) + PDQ(0,1,1,4)), # diferenciação com MA sazonal
    sarima.AR1I1   = ARIMA(producao ~ pdq(0,0,0) + PDQ(1,1,0,4)), # diferenciação com AR sazonal
  )

fit.agr |> pivot_longer(!setor, names_to="Modelo", values_to = "Parâmetros")
```

\

Modelos ordenados do melhor para o pior pelo AICc

```{r}
glance(fit.agr) |> select(.model,AIC:BIC) |> arrange(AICc)
```


Mesmo com os ajustes, o modelo sugerido pelo `auto.arima` continua sendo o melhor modelo para a série temporal de produção do setor agropecuário. 

\

### 2. Resíduos de treinamento


Vamos analisar os resíduos dos dados de treinamento do modelo selecionado para assegurar que:

1. Os resíduos do modelo não estão correlacionados entre si. Se existirem correlações entre os resíduos, então sobrou informação nos resíduos que deveria ser utilizada no cálculo das previsões. 

2. Os resíduos têm média zero. Se tiverem uma média diferente de zero, as previsões estão com viés. 

Qualquer modelo de previsão que não satisfaça estas propriedades dos resíduos de treinamento pode ser melhorado. Verificar essas propriedades é importante para ver se um modelo está utilizando todas as informações disponíveis nos dados para fazer a previsão ou se os resíduos ainda contêm padrões que poderiam ser modelados. Isso não significa que os modelos que satisfaçam estas propriedades não possam ser melhorados, já que é possível ter vários modelos de previsão diferentes para o mesmo conjunto de dados, todos satisfazendo estas propriedades. Mas se alguma destas propriedades não for satisfeita, então o modelo com certeza pode ser modificado para gerar melhores previsões. (Hyndman & Athanasopoulos, 2021)

Além destas duas propriedades essenciais, é útil (mas não necessário) que os resíduos também tenham as seguintes características:

a. Os resíduos têm variância constante. Isso é conhecido como “homoscedasticidade”.

b. Os resíduos são normalmente distribuídos.

Essas características facilitam o cálculo dos intervalos de previsão. Se os resíduos não forem normalmente distribuídos, os intervalos de previsão não serão confiáveis. Se os resíduos não tiverem variância constante, então os intervalos de previsão serão muito amplos em alguns períodos e muito estreitos em outros. Às vezes, a aplicação de uma transformação pode ajudar com essas propriedades. Caso contrário, geralmente há pouco que se possa fazer para garantir que os resíduos de treinamento tenham variância constante e uma distribuição normal. Em vez disso, é necessária uma abordagem alternativa para obter intervalos de previsão.


```{r}
gg_tsresiduals(fit.agr |> select(auto.arima))
```

Os resíduos do modelo sugerido pelo `auto.arima` parecem satisfazer as propriedades essenciais dos resíduos de treinamento. Não há correlação significativa entre os resíduos e a média dos resíduos é próxima de zero. O histograma dos resíduos parece se aproximar de uma normal. A variância dos resíduos parece aumentar nos períodos a partir de 2014 (isso coincide com os ciclos de "vales" observados na decomposição da tendência da série).


Além de observar o gráfico ACF, também podemos fazer um teste mais formal de autocorrelação considerando todo um conjunto de autocorrelações como um grupo, em vez de olhar cada um separadamente. Quando olhamos para o gráfico ACF para ver se cada pico está dentro dos limites exigidos, estamos implicitamente realizando múltiplos testes de hipóteses, cada um com uma pequena probabilidade de dar um falso positivo. Quando um número suficiente destes testes for realizado, é provável que pelo menos um dê um falso positivo, e assim poderíamos concluir que os resíduos têm alguma autocorrelação remanescente, quando na verdade não têm.

Então, é possível testar formalmente se as primeiras $ℓ$ autocorrelações são significativamente diferentes do que seria esperado de uma série estacionária. Um teste para um grupo de autocorrelações é chamado de teste *portmanteau*, de uma palavra francesa que descreve uma mala ou cabide carregando várias peças de roupa. Dois testes portmanteau bastante conhecidos são o [Box-Pierce]{.underline} e o [Ljung-Box]{.underline}. 

Ambos usam um limite de lag máximo $ℓ$ e o número de observações $T$. Uma regra de bolso é usar $ℓ=10$ para dados não sazonais e $ℓ=2s$ para dados sazonais, onde s é o período de sazonalidade. No entanto, o teste não é bom quando $ℓ$ for grande, portanto, se esses valores forem maiores que $T/5$, usa-se $ℓ=T/5$. (Hyndman & Athanasopoulos, 2021)

Com modelos ARIMA, testes de portmanteau mais precisos são obtidos se os graus de liberdade forem ajustados para levar em conta o número de parâmetros no modelo. Especificamente, usamos $ℓ−K$ graus de liberdade no teste, onde $K$ é o número de parâmetros AR e MA no modelo. Portanto, para o modelo selecionado, $K=p+q+P+Q=0+1+0+1=2$. O valor de $K$ é passado para a função pelo argumento de degrees of freedom `dof` como pode-se ver a seguir:


```{r}
augment(fit.agr) |> filter(.model=="auto.arima") |> features(.innov, ljung_box, lag=8, dof=2)

augment(fit.agr) |> filter(.model=="auto.arima") |> features(.innov, box_pierce, lag=8, dof=2)
```


Tanto para Ljung-Box quanto Box-Pierce, os resultados não são significativos (ou seja, os `p-values` são bem superiores a $0,05$). Assim, podemos concluir que os resíduos não são distinguíveis de uma série estacionária (ruído branco). Isso confirma que o modelo ARIMA selecionado é adequado para a série temporal de produção do setor agropecuário.


\

### 4. Forecast

Então vamos usá-lo para fazer a previsão e analisar seu desempenho contra os dados de teste.

\

```{r fig.asp=.5}
fcst.agr <- fit.agr |> select(setor, auto.arima, random.walk) |> 
  forecast(h=16)

fcst.agr |> 
  autoplot(ts1.test |> filter(year(Trimestre)>=2015), level=NULL, linewidth=.8) +
  labs(title = "Previsão de produção trimestral, Agropecuária",
       x = NULL)
```


\



```{r}
accuracy(fcst.agr, ts1.test) |> select(-.type) |>
  arrange(MAPE) |> select(.model:MAPE) |>
  gt(rowname_col="stub", locale="pt") |> sub_missing() |>
  fmt_number(c(ME,RMSE,MAE), decimals=2) |> 
  fmt_number(c(MPE,MAPE), decimals=1) |> 
  tab_options(
    heading.align="left", heading.title.font.size=pct(110), heading.subtitle.font.size=pct(90),
    column_labels.font.weight="bold", column_labels.font.size=pct(80),
    column_labels.text_transform="uppercase", column_labels.background.color="gray95",
    data_row.padding=px(2), row_group.padding=px(2), row_group.font.weight="bold",
    table.font.size=pct(90), source_notes.font.size = pct(70),
  ) |> 
  tab_header(title = md("**Medidas de acurácia das previsões sobre a base de teste**"))
```

\

Medidas de acurácia na mesma escala dos dados originais:

-   [Mean error (ME):]{.underline} A média dos erros de previsão. Expresso na mesma escala dos dados.\

-   [Root mean squared error (RMSE):]{.underline} A raiz quadrada da média dos erros de previsão ao quadrado. Expresso na mesma escala dos dados.\

-   [Mean absolute error (MAE):]{.underline} A média dos valores absolutos dos erros de previsão. Expresso na mesma escala dos dados.\

\

Medidas de acurácia independentes da escala dos dados originais:

-   [Mean percentage error (MPE):]{.underline} A média dos erros de previsão como uma porcentagem dos valores observados. Independe da escala dos dados.\

-   [Mean absolute percentage error (MAPE):]{.underline} A média dos valores absolutos dos erros de previsão como uma porcentagem dos valores observados. Independe da escala dos dados.\



\

A seguir vamos modelar e fazer previsões para os três setores da economia: Agropecuária, Indústria e Serviços.

\

## Todos os setores


Separa datasets de treino e teste

```{r}
ts1.train <- ts1 |> filter(year(Trimestre)<=2019)
ts1.test <- ts1 
```


\


### 1. Modelagem



```{r warning=FALSE}
fit <- ts1.train |> model(autoARIMA = ARIMA(producao))

fit |> pivot_longer(!setor, names_to = "Modelo", values_to = "Parâmetros")
```

\

Modelos ordenados por AICc

```{r}
glance(fit) |> select(setor,.model,AIC:BIC) |> arrange(AICc)
```


\


### 2. Resíduos de treinamento

Testa os resíduos de treinamento da Indústria e de Agropecuária com 2 graus de liberdade.

```{r}
augment(fit) |> features(.innov, ljung_box, lag=8, dof=2) |> filter(setor != "Serviços")
augment(fit) |> features(.innov, box_pierce, lag=8, dof=2) |> filter(setor != "Serviços")
```

Tanto para Ljung-Box quanto Box-Pierce, os resultados não são significativos (ou seja, os `p-values` são bem superiores a $0,05$). Assim, podemos concluir que os resíduos não são distinguíveis de uma série estacionária (ruído branco). 



\

Testa os resíduos de treinamento do setor de Serviços com 4 graus de liberdade.


```{r}
augment(fit) |> features(.innov, ljung_box, lag=8, dof=4) |> filter(setor == "Serviços")
augment(fit) |> features(.innov, box_pierce, lag=8, dof=4) |> filter(setor == "Serviços")
```

Tanto para Ljung-Box quanto Box-Pierce, os `p-values` são inferiores a $0,05$. Assim, podemos concluir que os resíduos ainda podem conter padrões que possam ser incorporados no modelo para melhorar as previsões. Pode valer a pena continuar testando alternativas para capturar esses padrões.

Vamos visualizar essas previsões dos modelos contra a série de testes para tentar entender como esses modelos estão se saindo.


\

### 4. Forecast


```{r fig.asp=1}
fcst <- fit |> forecast(h=16)

fcst |> 
  autoplot(ts1.test |> filter(year(Trimestre)>=2015), level=NULL, linewidth=.8, alpha=.5) +
  labs(title = "Previsão de produção trimestral", x = NULL)
```


\


```{r}
accuracy(fcst, ts1.test) |> 
  arrange(MAPE) |> select(.model:MAPE) |>
  gt(rowname_col="stub", locale="pt") |> sub_missing() |>
  fmt_number(c(ME,RMSE,MAE), decimals=2) |> 
  fmt_number(c(MPE,MAPE), decimals=1) |> 
  tab_options(
    heading.align="left", heading.title.font.size=pct(110), heading.subtitle.font.size=pct(90),
    column_labels.font.weight="bold", column_labels.font.size=pct(80),
    column_labels.text_transform="uppercase", column_labels.background.color="gray95",
    data_row.padding=px(2), row_group.padding=px(2), row_group.font.weight="bold",
    table.font.size=pct(90), source_notes.font.size = pct(70),
  ) |> 
  tab_header(title = md("**Medidas de acurácia das previsões comparadas à base de teste**"))
```




\


# FIM

\

*Antes de fazer sua entrega, reúna todos os arquivos relativos ao seu Projeto de Disciplina em um único arquivo no formato .zip e poste no Moodle. Utilize o seu nome para nomear o arquivo, identificando também a disciplina, como no exemplo: “nomedoaluno_nomedadisciplina_pd.zip”.*

\

# Referências bibliográficas

\

Cerqueira, V. (2023) *3 Types of Seasonality and How to Detect Them*. Disponível em: [https://towardsdatascience.com/3-types-of-seasonality-and-how-to-detect-them-7c9beedf2f8e]. Acessado em `r format(Sys.time(), '%d/%m/%Y')`.


\

Diachkov, D. 2023. *Time Series Analysis in R: ARIMA family*. Medium Article. Disponível em: [[https://medium.com/\@the_lord_of_the_R/time-series-analysis-in-r-arima-family-fd901f1412a8](https://medium.com/@the_lord_of_the_R/time-series-analysis-in-r-arima-family-fd901f1412a8){.uri}]. Acessado em `r format(Sys.time(), '%d/%m/%Y')`.

\

Hyndman, R. J. & Athanasopoulos, G. 2021. [*Capítulo 9 - Arima models*](https://otexts.com/fpp3/arima.html) e [*Capítulo 5.8 - Evaluating point forecast accuracy*](https://otexts.com/fpp3/accuracy.html) de *Forecasting: principles and practice, 3rd edition*. OTexts: Melbourne, Australia. Disponível em: [<https://otexts.com/fpp3/>]. Acessado em `r format(Sys.time(), '%d/%m/%Y')`.

\

Kwiatkowski, D., Phillips, P. C. B., Schmidt, P., & Shin, Y. 1992. *Testing the null hypothesis of stationarity against the alternative of a unit root: How sure are we that economic time series have a unit root?* Journal of Econometrics, 54(1-3), 159–178. [DOI: https://doi.org/10.1016/0304-4076(92)90104-Y]

\

Parzen, E. (2015). *Stochastic Processes*. Courier Dover Publications. pp. 7, 8. 336p. ISBN 978-0-486-79688-8.

\

Peixeiro, M. 2019. *The Complete Guide to Time Series Analysis and Forecasting*. Towards Data Science Article. Disponível em: [<https://medium.com/towards-data-science/the-complete-guide-to-time-series-analysis-and-forecasting-70d476bfe775>]. Acessado em `r format(Sys.time(), '%d/%m/%Y')`.
